stepsmean
stepsmedian
activityfull <- activity
for(i in 1:nrow(activityfull)){
if(is.na(activityfull[i,1])){
activityfull[i,1] <- intervalavg[which(grepl(paste('^', activityfull[i,3], '$', sep = ""), intervalavg$interval)),2]
}
}
dailytotalfull <- ddply(activityfull, .(date), summarize, total_steps = sum(steps, na.rm = TRUE))
hist(dailytotalfull$total_steps, main = "Total Number of Steps Taken with Imputed Values", xlab = "Total Steps Per Day")
stepsmeanfull <- round(mean(dailytotalfull$total_steps, na.rm = T))
stepsmedianfull <- round(median(dailytotalfull$total_steps, na.rm = T))
2+3
5/2
2.5+4/2
2+3+4/3
6.5/2
9/3
?qunif
x <- 1:4
p <- x/sum(x)
temp <- rbind(x, p)
rownames(temp) <- c("X", "Prob")
temp
mean(temp)
mean(x)
mean(p)
sum(x ^ 2 * p) - sum(x * p) ^ 2
2.5*.25
library(swirl)
rm(list=ls())
?install.swirl
swirl()
library(swirl)
install_from_swirl("Statistical Inference")
swirl()
?qnorm
qnorm(.95, 100, 10/sqrt(50))
?pbinom
pbinom(4, prob = .5, size = 6, lower.tail = FALSE) * 100
pbinom(3, prob = .5, size = 5, lower.tail = FALSE) * 100
?qnorm
x <- 3
t <- 3
x <- 5
lambda <- x/t
round(lambda + c(-1, 1) * qnorm(0.975) * sqrt(lambda/t), 3)
?ppois
ppois(10, lambda, lower.tail=F)
round(ppois(10, lambda, lower.tail=F))
ppois(10, lambda, lower.tail=F)*100
ppois(10, lambda = 5 * 3)
lambda = 0.2
n = 40
rexp(n, lambda)
numsims = 1000
?set.seed
set.seed(1122)
hist(runif(1000))
mns = NULL
for (i in 1 : 1000) mns = c(mns, mean(runif(40)))
hist(mns)
hist(rexp(1000, lambda))
means = NULL
for (i in 1 : numsims) means = c(means, mean(rexp(n, lambda)))
hist(means)
theovar <- 1/lambda^2
lambda^2
1/.04
?line
x <- seq(2,8,length=200)
?seq
# create some data to work with
x = rnorm(1000);
# overlay histogram, empirical density and normal density
p0 = qplot(x, geom = 'blank') +
geom_line(aes(y = ..density.., colour = 'Empirical'), stat = 'density') +
stat_function(fun = dnorm, aes(colour = 'Normal')) +
geom_histogram(aes(y = ..density..), alpha = 0.4) +
scale_colour_manual(name = 'Density', values = c('red', 'blue')) +
opts(legend.position = c(0.85, 0.85))
print(p0)
load(ggplot2)
library(ggplot2)
# create some data to work with
x = rnorm(1000);
# overlay histogram, empirical density and normal density
p0 = qplot(x, geom = 'blank') +
geom_line(aes(y = ..density.., colour = 'Empirical'), stat = 'density') +
stat_function(fun = dnorm, aes(colour = 'Normal')) +
geom_histogram(aes(y = ..density..), alpha = 0.4) +
scale_colour_manual(name = 'Density', values = c('red', 'blue')) +
opts(legend.position = c(0.85, 0.85))
print(p0)
y <- dnorm(x,mean=1/lambda, sd=(1/lambda) / sqrt(num_samples))
y <- dnorm(x,mean=1/lambda, sd=(1/lambda) / sqrt(n))
plot(x,y)
x <- seq(2,8,length=200)
y <- dnorm(x,mean=1/lambda, sd=(1/lambda) / sqrt(n))
plot(x,y)
min(means)
x<-seq(min(means), max(means), 500)
y <- dnorm(x,mean=1/lambda, sd=(1/lambda) / sqrt(n))
plot(x,y)
x<-seq(min(means), max(means), 500)
x<-seq(min(means), max(means), length = 500)
y <- dnorm(x,mean=1/lambda, sd=(1/lambda) / sqrt(n))
plot(x,y)
max(y)
max(y)*1000
max(y)*500
library(datasets)
?datasets
library(help = "datasets")
toothgrowth <- ToothGrowth
str(toothgrowth)
hist(toothgrowth$len)
hist(toothgrowth$dose)
with(toothgrowth, plot(len, dose))
with(toothgrowth, plot(dose, len))
with(toothgrowth, boxplot(dose, len))
with(toothgrowth, plot(dose, len))
with(toothgrowth, plot(sup, len))
with(toothgrowth, plot(sup, len))
with(toothgrowth, plot(supp, len))
with(toothgrowth, plot(supp, dose))
quantile(toothgrowth$len)
?ToothGrowth
require(graphics)
coplot(len ~ dose | supp, data = ToothGrowth, panel = panel.smooth,
xlab = "ToothGrowth data: length vs dose, given type of supplement")
library(swirl)
ls()
rm(list=ls())
swirl()
install_from_swirl("Statistical Inference")
swirl()
swirl()
rm(list=ls())
library(swirl)
swirl()
33/36
deck
52
4/52
0
12/52
3/52
2/52
2/2
2/11
22/51
2/51
.5*.8*1.6
64
64%
info()
.64
?mypdf()
mypdf()
mypdf
mypdf(1.6)
integrate(mypdf, 1.6)
integrate(mypdf,0,1.6)
1
2
1/4
2
1
.25/4
x^2=4*.5=2
1.6^2
1.6^2/4
info()
.5
skip()
swirl()
.997*.001
.985*1-.001
.985*.999
.985*.001
.985*(1-.997)
(1-.001)*(1-.985)
(.997*.001)/((1-.001)*(1-.985))
(.997*.001)/((.997*.001)+(.015-.999))
(.997*.001)/((.997*.001)+(.015*.999))
View(toothgrowth)
g1 <- toothgrowth$len[toothgrowth$supp %in% "VC"]
g2 <- toothgrowth$len[toothgrowth$supp %in% "OJ"]
difference <- g2 - g1
mn <- mean(difference)
s <- sd(difference)
n <- length(g2)
n
?ToothGrowth
swirl()
library(swirl)
swirl()
3.5
expect_dice
dice_high
expect_dice(dice_high)
expect_dice(dice_low)
edh*edl*.5
(edh+edl)*.5
integrate(myfunc, 0, 2)
spop
mean(spop)
allsam
apply(allsam, 1, mean)
mean(smeans)
0
exit()
info()
bye()
swirl()
dice_sqr
ex2_fair <- sum(dice_fair^2)
ex2_fair <- sum(dice_fair * dice_sqr)
ex2_fair-3.5^2
edh-3.5^2
sum(dice_high * dice_sqr)-edh^2
sd(apply(matrix(rnorm(10000),1000),1,mean))
1/sqrt(10)
1/sqrt(120)
sd(apply(matrix(runif(10000),1000),1,mean))
2/sqrt(10)
sd(apply(matrix(rpois(10000,4),1000),1,mean))
1/2*sqrt(10)
1/(2*sqrt(10))
sd(apply(matrix(sample(0:1,10000,TRUE),1000),1,mean))
g1 <- (140, 138, 150, 148, 135)
g1 <- c(140, 138, 150, 148, 135)
g2<- c(132,135,151,146,130)
?t.test
t.test(g1,g2)
qt(.95, 8)
1.86
1.86*10
pt(qt(.95, 3), 4, lower.tail = FALSE)
t.test(g1,g2, alternative = "two-sided")
t.test(g1,g2, alternative = "two.sided")
t.test(mu=1100)
t.test(x=9, mu=1100)
1100 + c(-1, 1) * qt(.975, 9-1) * 30 / sqrt(9)
pnorm(2, prob = .5, size = 4, lower.tail = FALSE)
?pnorm
pnorm(2)
pbinom(2, prob = .5, size = 4, lower.tail = FALSE)
You believe the coin that you're flipping is biased towards heads. You get 55 heads out of 100 flips.
What's the exact relevant pvalue to 4 decimal places (expressed as a proportion)?
Would you reject a 1 sided hypothesis at α=.05? (0 for no 1 for yes)?
Use pbinom for a hypothesis that p=.5 veruss p>.5 where p is the binomial success probability.
A web site was monitored for a year and it received 520 hits per day. In the first 30 days in the next year, the site received 15,800 hits. Assuming that web hits are Poisson.
Give an exact one sided P-value to the hypothesis that web hits are up this year over last to four significant digits (expressed as a proportion).
Does the one sided test reject (0 for no 1 for yes)?
Consider using ppois with λ=520∗30. Note this is nearly exactly Gaussian, so one could get away with the Gaussian calculation.
Suppose that in an AB test, one advertising scheme led to an average of 10 purchases per day for a sample of 100 days, while the other led to 11 purchaces per day, also for a sample of 100 days. Assuming a common standard deviation of 4 purchases per day. Assuming that the groups are independent and that they days are iid, perform a Z test of equivalence.
What is the P-value reported to 3 digits expressed as a proportion?
Do you reject the test? (0 for no 1 for yes).
ppois(15800 - 1, lambda = 520 * 30, lower.tail = FALSE)
)
)
x
""""
ppois(15800 - 1, lambda = 520 * 30, lower.tail = FALSE)
ppois(1787 - 1, lambda = 1 * 10, lower.tail = FALSE)
ppois(1787 - 1, lambda = 1/100 * 10, lower.tail = FALSE)
?ppois
ppois(10 - 1, lambda = 1/100 * 1787, lower.tail = FALSE)
ppois(10 - 1, lambda = 178.7, lower.tail = FALSE)
ppois(10 - 1, lambda = 1/178.7, lower.tail = FALSE)
ppois(10 - 1, lambda = 1787/100, lower.tail = FALSE)
?t.test
?pnorm
mn = -3-1
std = 1.5-1.8
pnorm(mean=mn, sd=std)
pnorm(.95, mean=mn, sd=std)
m1 <- -3; m2 <- 1
n1 <- n2 <- 9
s <- std
se <- s * sqrt(1 / n1 + 1 / n2)
ts <- (m2 - m1) / se
pv <- 2 * pnorm(-abs(ts))
pv
ts
?pt
pt(.95,17)
qt(.95,17)
qt(.975,17)
(mn*sqrt(18))/std
(mn*sqrt(18))/-1.8
power.t.test(n = 100, delta = .01, sd = .04, type = "one.sample", alt = "one.sided")$power
power.t.test(power = .9, delta = .01, sd = .04, type = "one.sample", alt = "one.sided")$n
?qt
pt(8.48,18, lower.tail=F)
pt(8.48,18, lower.tail=T)
pt(-2.35,18, lower.tail=T)
pt(ts,17)
pt(ts,17, lower.tail=t)
pt(ts,17, lower.tail=T)
pt(ts,17, lower.tail=F)
m1 <- -3; m2 <- 1
n1 <- n2 <- 9
s <- 1.8
se <- s * sqrt(1 / n1 + 1 / n2)
ts <- (m2 - m1) / se
pv <- 2 * pnorm(-abs(ts))
pt(ts, 17)
pt(ts, 17, lower.tail=T)
pt(ts, 17, lower.tail=F)
m1 <- -3; m2 <- 1
n1 <- n2 <- 9
s <- 1.8
se <- s * sqrt(18)
ts <- (m2 - m1) / se
pv <- 2 * pnorm(-abs(ts))
pt(ts, 17, lower.tail=F)
pt(ts, 17, lower.tail=T)
g1<- c(140,138,150,148,135)
g2<- c(132,135,151,146,130)
?pnorm
?pt
t.test(g1-g2)
?t.test
t.test(g1-g2, alternative = "two.sided")
pt(-5.121,17)
pt(-5.121,8)
library(swirl)
ls()
rm(list=ls())
swirl()
library(swirl)
swirl()
choose(5,3)*.8^3*(.2)^2
x=3,4,5
x=c(3,4,5)
choose(5,x)*(.8)^x*(.2)^(5-x)
sum(choose(5,x)*(.8)^x*(.2)^(5-x))
binom(2,5,.8,lower,tail=F)
pbinom(2,5,.8,lower,tail=F)
pbinom(2,5,.8,lower.tail=F)
pbinom(2,size=5,prob=.8,lower.tail=FALSE)
qnorm(prob)
qnorm(10)
qnorm(.1)
0
qnorm(3,2)
qnorm(.975, 3,2)
3*+2*1.96
3+2*1.96
pnorm(mean = 1020, sd=50)
pnorm(1200, mean = 1020, sd=50, lower.tail=F)
pnorm(1200,mean=1020,sd=50,lower.tail=FALSE)
f
(1200-1020)/50
pnorm((1200-1020)/50,lower.tail=FALSE)
qnorm(.75, 1020, 50)
.75
pnorm(qnorm(.53))
qnorm(pnorm(.53))
ppois(3,2.5*4)
pbinom(5,1000, .1)
pbinom(5,1000, .01)
ppois(.01, 5*1000)
ppois(5, .01*1000)
ppois(5,1000*.01)
coinplot(10)
coinPlot(10)
coinPlot(10000)
wd()
getwd()
x <- read.csv("./data/bk_dowloand.csv")
x <- read.csv("./data/bk_download.csv")
head(x)
x <- x[,c(3,5,7)]
head(x)
x <- read.csv("./data/bk_dowloand.csv", header = F)
x <- x[,c(3,5,7)]
x <- read.csv("./data/bk_download.csv", header = F)
x <- x[,c(3,5,7)]
head(x)
for (i in 1:length(x$V3)){print x[i, 1]}
for i in 1:length(x$V3){print x[i, 1]}
length(x$V3)
i=1
print x[i, 1]
print x
print(x)
for (i in 1:length(x$V3)){
print (x[i, 1])
}
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
install.packages("AppliedPredictiveModeling")
install.packages("caret")
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis, p = 0.50)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
x <- read.csv("./data/bk_download.csv", header = F)
adData = data.frame(diagnosis,predictors)
testIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
training = adData[-testIndex,]
testing = adData[testIndex,]
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
hist(training$Superplasticizer)
hist(log(training$Superplasticizer))
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
library(manipulate)
myPlot <- function(s) {
plot(cars$dist - mean(cars$dist), cars$speed - mean(cars$speed))
abline(0, s)
}
install.packages('devtools')
devtools::install_github('rstudio/shinyapps')
install.packages('Rtools')
shinyapps::setAccountInfo(name='cdo03c', token='1623B6C93B8AA6B18CCABB859393ED7A', secret='5D1IyQtWztqQYIi2kHW1nOgj7TsJo4F73mmc2KcO')
install.packages("viridis")
devtools::install_github("ropensci/plotly")
plotly:::verify("cdo03c")
plotly:::verify("edro5aai6l")
Sys.setenv("plotly_username"="cdo03c")
Sys.setenv("plotly_api_key"="edro5aai6l")
install.packages(c("lme4", "manipulate", "randomForest"))
getwd()
manipulate(myPlot, s = slider(0, 2, step = 0.1))
library(manipulate)
manipulate(myPlot, s = slider(0, 2, step = 0.1))
manipulate(myPlot(s), s = slider(0, 2, step = 0.1))
library(rcharts)
library(rCharts)
install.packages("rCharts")
library(rCharts)
```{r, eval=FALSE}
?rev
getwd()
install.packages(c("car", "caret", "coda", "curl", "DiagrammeR", "dplyr", "effects", "foreach", "forecast", "Formula", "geoBayes", "geoCount", "geoR", "geoscale", "geosphere", "ggmap", "ggplot2", "git2r", "Hmisc", "iterators", "jsonlite", "KernSmooth", "lazyeval", "lme4", "lmtest", "lubridate", "manipulate", "mapproj", "maps", "multcomp", "mvtnorm", "packrat", "pbkrtest", "plotly", "RandomFields", "RandomFieldsUtils", "randomForest", "Rcmdr", "RcmdrMisc", "Rcpp", "RcppArmadillo", "rgl", "RgoogleMaps", "rJava", "rmarkdown", "RODBC", "roxygen2", "rstudioapi", "sandwich", "sem", "sp", "spam", "splancs", "stringdist", "stringi", "tcltk2", "testthat", "tidyr", "viridis", "XLConnect", "XML", "xtable"))
getwd()
setwd("~/GitHub/Titanic_Models")
getwd()
if(!file.exists("./train.csv")){download.file(url = "https://www.kaggle.com/c/titanic/download/train.csv", destfile = "./train.csv")}
if(!file.exists("./test.csv")){download.file(url = "https://www.kaggle.com/c/titanic/download/test.csv", destfile = "./test.csv")}
##Load dependencies and set random seed
library(caret, quietly=TRUE)
library(randomForest)
library(pROC)
set.seed(2233)
##Load the training and test data
training <- read.csv("./train.csv")
testing <- read.csv("./test.csv")
View(testing)
View(training)
summary(testing)
training$Survived <- as.factor(training$Survived)
training$Age[is.na(training$Age)] <- mean(training$Age)
training$Fare[is.na(training$Fare)] <- median(training$Fare, na.rm=T)
training$Embarked[training$Embarked==""]<- "S"
training$Embarked<- as.factor(training$Embarked)
training$Sex <- as.factor(training$Sex)
training$Pclass <- as.factor(training$Pclass)
summary(testing)
training$Pclass <- as.factor(training$Pclass)
summary(training)
plot(training$Fare, training$Pclass)
boxplot(training$Fare, training$Pclass)
boxplot(log(training$Fare), training$Pclass)
testing$Age[is.na(testing$Age)] <- mean(testing$Age)
testing$Fare[is.na(testing$Fare)] <- median(testing$Fare, na.rm=T)
testing$Embarked[testing$Embarked==""]<- "S"
testing$Embarked<- as.factor(testing$Embarked)
testing$Sex <- as.factor(testing$Sex)
testing$Pclass <- as.factor(testing$Pclass)
##Create new features
training$FamSize <- training$SibSp + training$Parch + 1
training$CabinIdent <- as.factor(ifelse(training$Cabin=="", 0, 1))
testing$FamSize <- testing$SibSp + testing$Parch + 1
testing$CabinIdent <- as.factor(ifelse(testing$Cabin=="", 0, 1))
str(training)
training$FamSize <- as.factor(training$SibSp + training$Parch + 1)
str(training)
training$FamSize <- training$SibSp + training$Parch + 1
str(training)
